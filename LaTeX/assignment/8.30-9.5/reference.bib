@misc{yang2017deep,
	title={Deep Joint Rain Detection and Removal from a Single Image}, 
	author={Wenhan Yang and Robby T. Tan and Jiashi Feng and Jiaying Liu and Zongming Guo and Shuicheng Yan},
	year={2017},
	eprint={1609.07769},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@incollection{McDonagh_2017,
	doi = {10.1007/978-3-319-67564-0_12},
	
	url = {https://doi.org/10.1007%2F978-3-319-67564-0_12},
	
	year = 2017,
	publisher = {Springer International Publishing},
	
	pages = {116--126},
	
	author = {Steven McDonagh and Benjamin Hou and Amir Alansary and Ozan Oktay and Konstantinos Kamnitsas and Mary Rutherford and Jo V. Hajnal and Bernhard~ Kainz},
	
	title = {Context-Sensitive Super-Resolution for Fast Fetal Magnetic Resonance Imaging},
	
	booktitle = {Lecture Notes in Computer Science}
}

@article{Lv2018MBLLEN,
	
	title={MBLLEN: Low-light Image/Video Enhancement Using CNNs},
	
	author={Feifan Lv, Feng Lu, Jianhua Wu and Chongsoon Lim},
	
	journal={British Machine Vision Conference},
	
	year={2018}
	
}

@misc{chen2018learning,
	title={Learning to See in the Dark}, 
	author={Chen Chen and Qifeng Chen and Jia Xu and Vladlen Koltun},
	year={2018},
	eprint={1805.01934},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@ARTICLE{4767851,
	author={Canny, John},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={A Computational Approach to Edge Detection}, 
	year={1986},
	volume={PAMI-8},
	number={6},
	pages={679-698},
	doi={10.1109/TPAMI.1986.4767851}}
	
@inproceedings{10.1145/1836845.1836920,
	author = {Dong, Xuan and Pang, Yi (Amy) and Wen, Jiangtao (Gene)},
	title = {Fast Efficient Algorithm for Enhancement of Low Lighting Video},
	year = {2010},
	isbn = {9781450303934},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1836845.1836920},
	doi = {10.1145/1836845.1836920},
	abstract = {We describe a novel and effective video enhancement algorithm for low lighting video. The algorithm works by first inverting the input low-lighting video and then applying an image de-haze algorithm on the inverted input. To facilitate faster computation and improve temporal consistency, correlations between temporally neighboring frames are utilized. Simulations using naive implementations of the algorithm show good enhancement results and 2x speed-up as compared with frame-wise enhancement algorithms, with further improvements in both quality and speed possible.},
	booktitle = {ACM SIGGRAPH 2010 Posters},
	articleno = {69},
	numpages = {1},
	keywords = {low lighting video enhancement, de-hazing, invert},
	location = {Los Angeles, California},
	series = {SIGGRAPH '10}
}

@ARTICLE{557356,
	author={Jobson, D.J. and Rahman, Z. and Woodell, G.A.},
	journal={IEEE Transactions on Image Processing}, 
	title={Properties and performance of a center/surround retinex}, 
	year={1997},
	volume={6},
	number={3},
	pages={451-462},
	doi={10.1109/83.557356}}
	
@ARTICLE{7782813,
	author={Guo, Xiaojie and Li, Yu and Ling, Haibin},
	journal={IEEE Transactions on Image Processing}, 
	title={LIME: Low-Light Image Enhancement via Illumination Map Estimation}, 
	year={2017},
	volume={26},
	number={2},
	pages={982-993},
	doi={10.1109/TIP.2016.2639450}}

@misc{lore2016llnet,
	title={LLNet: A Deep Autoencoder Approach to Natural Low-light Image Enhancement}, 
	author={Kin Gwn Lore and Adedotun Akintayo and Soumik Sarkar},
	year={2016},
	eprint={1511.03995},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}