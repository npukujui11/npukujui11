\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Pre-Knowledge}{2}{part.1}\protected@file@percent }
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Paper Reading}{2}{part.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}LLIE}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}(2023.1)Illumination estimation for nature preserving low-light image enhancement}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{低光图像增强中保留自然光的照度估计}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(The Visual Computer 3区) doi: 10.1007/s00371-023-02770-9}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Research Background}{2}{subsubsection.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}Contribution}{2}{subsubsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3}Approach}{3}{subsubsection.1.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.4}Future}{3}{subsubsection.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}(2023.7)Division Gets Better: Learning Brightness-Aware and Detail-Sensitive Representations for Low-Light Image Enhancement}{3}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{分割可以变得更好：学习亮度感知和细节敏感的表示为低光图像增强}{3}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(CVPR 2023) doi: 10.48550/arXiv.2307.09104}{3}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Research Background}{3}{subsubsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Contribution}{3}{subsubsection.1.2.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: RGB-low light1}{{\caption@xref {fig: RGB-low light1}{ on input line 173}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: RGB-low light1}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: R1}{{\caption@xref {fig: R1}{ on input line 178}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: R1}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: G1}{{\caption@xref {fig: G1}{ on input line 183}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: G1}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: B1}{{\caption@xref {fig: B1}{ on input line 188}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: B1}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Y1}{{\caption@xref {fig: Y1}{ on input line 193}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Y1}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Cb1}{{\caption@xref {fig: Cb1}{ on input line 198}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Cb1}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Cr1}{{\caption@xref {fig: Cr1}{ on input line 203}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Cr1}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Ours1}{{\caption@xref {fig: Ours1}{ on input line 208}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Ours1}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: RGB-low light2}{{\caption@xref {fig: RGB-low light2}{ on input line 214}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: RGB-low light2}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: R2}{{\caption@xref {fig: R2}{ on input line 219}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: R2}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: G2}{{\caption@xref {fig: G2}{ on input line 224}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: G2}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: B2}{{\caption@xref {fig: B2}{ on input line 229}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: B2}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Y2}{{\caption@xref {fig: Y2}{ on input line 234}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Y2}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Cb2}{{\caption@xref {fig: Cb2}{ on input line 239}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Cb2}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Cr2}{{\caption@xref {fig: Cr2}{ on input line 244}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Cr2}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Ours2}{{\caption@xref {fig: Ours2}{ on input line 249}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Ours2}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: RGB-low light3}{{\caption@xref {fig: RGB-low light3}{ on input line 256}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: RGB-low light3}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: R3}{{\caption@xref {fig: R3}{ on input line 262}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: R3}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: G3}{{\caption@xref {fig: G3}{ on input line 268}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: G3}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: B3}{{\caption@xref {fig: B3}{ on input line 274}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: B3}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Y3}{{\caption@xref {fig: Y3}{ on input line 280}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Y3}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Cb3}{{\caption@xref {fig: Cb3}{ on input line 286}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Cb3}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Cr3}{{\caption@xref {fig: Cr3}{ on input line 292}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Cr3}{{}{4}{Research Background}{figure.caption.1}{}}
\newlabel{fig: Our3}{{\caption@xref {fig: Our3}{ on input line 298}}{4}{Research Background}{figure.caption.1}{}}
\newlabel{sub@fig: Our3}{{}{4}{Research Background}{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces   Low-light images and their luminance and chrominance decomposition. The first four columns show original low-light images in RGB space and their RGB channel decomposition, the fifth column shows luminance (Y) channels of low-light images, the sixth and seventh columns are chrominance (CbCr) components of low-light images, and the last column exhibits the enhanced images by our method. We can obviously observe that three channels of RGB space indicate indistinguishable distortion patterns, and Y and CbCr components reveal distinctly different distortion patterns. \relax }}{4}{figure.caption.1}\protected@file@percent }
\newlabel{fig: Low-light images and their luminance and chrominance decomposition}{{1}{4}{Low-light images and their luminance and chrominance decomposition. The first four columns show original low-light images in RGB space and their RGB channel decomposition, the fifth column shows luminance (Y) channels of low-light images, the sixth and seventh columns are chrominance (CbCr) components of low-light images, and the last column exhibits the enhanced images by our method. We can obviously observe that three channels of RGB space indicate indistinguishable distortion patterns, and Y and CbCr components reveal distinctly different distortion patterns. \relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}Approach}{4}{subsubsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.4}Future}{4}{subsubsection.1.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}(2023.3)Advanced RetinexNet: A fully convolutional network for low-light image enhancement}{4}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Advanced RetinexNet：用于弱光图像增强的全卷积网络}{4}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(Signal Processing: Image Communication 二区) doi: 10.1016/j.image.2022.116916}{4}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Research Background}{4}{subsubsection.1.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces   The overview of the proposed LCDBNet. The input images are transformed from RGB space to YCbCr space. Luminance and chrominance components are fed into LAN and CRN, respectively. Then, their outputs are fused in FN to derive the enhanced results. Finally, the enhanced images are converted back to RGB space. \relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig: LCDBNet}{{2}{5}{The overview of the proposed LCDBNet. The input images are transformed from RGB space to YCbCr space. Luminance and chrominance components are fed into LAN and CRN, respectively. Then, their outputs are fused in FN to derive the enhanced results. Finally, the enhanced images are converted back to RGB space. \relax }{figure.caption.2}{}}
\newlabel{fig: Input1}{{\caption@xref {fig: Input1}{ on input line 372}}{5}{Research Background}{figure.caption.3}{}}
\newlabel{sub@fig: Input1}{{}{5}{Research Background}{figure.caption.3}{}}
\newlabel{fig: LLME1}{{\caption@xref {fig: LLME1}{ on input line 377}}{5}{Research Background}{figure.caption.3}{}}
\newlabel{sub@fig: LLME1}{{}{5}{Research Background}{figure.caption.3}{}}
\newlabel{fig: SRIE1}{{\caption@xref {fig: SRIE1}{ on input line 382}}{5}{Research Background}{figure.caption.3}{}}
\newlabel{sub@fig: SRIE1}{{}{5}{Research Background}{figure.caption.3}{}}
\newlabel{fig: Our1}{{\caption@xref {fig: Our1}{ on input line 387}}{5}{Research Background}{figure.caption.3}{}}
\newlabel{sub@fig: Our1}{{}{5}{Research Background}{figure.caption.3}{}}
\newlabel{fig: Input2}{{3a}{5}{Input\relax }{figure.caption.3}{}}
\newlabel{sub@fig: Input2}{{a}{5}{Input\relax }{figure.caption.3}{}}
\newlabel{fig: LLME2}{{3b}{5}{LLME\relax }{figure.caption.3}{}}
\newlabel{sub@fig: LLME2}{{b}{5}{LLME\relax }{figure.caption.3}{}}
\newlabel{fig: SRIE2}{{3c}{5}{SRIE\relax }{figure.caption.3}{}}
\newlabel{sub@fig: SRIE2}{{c}{5}{SRIE\relax }{figure.caption.3}{}}
\newlabel{fig: Our2}{{3d}{5}{Our\relax }{figure.caption.3}{}}
\newlabel{sub@fig: Our2}{{d}{5}{Our\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces   Examples of low-light image enhanced results. The proposed method can not only improve the contrast of the image but also suppress the noise and artifacts in the dark regions. LIME generates color distorted results and causes noise amplification. SRIE generates under-enhancement results. \relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig: Examples of LLIE}{{3}{5}{Examples of low-light image enhanced results. The proposed method can not only improve the contrast of the image but also suppress the noise and artifacts in the dark regions. LIME generates color distorted results and causes noise amplification. SRIE generates under-enhancement results. \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Contribution}{6}{subsubsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}Approach}{6}{subsubsection.1.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces   The overall network architecture of our proposed method. \relax }}{6}{figure.caption.4}\protected@file@percent }
\newlabel{fig: Advanced RetinexNet}{{4}{6}{The overall network architecture of our proposed method. \relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces   The proposed Decom-Net architecture. The Decom-Net decomposes the input image into reflectance and illumination and can suppress the noise in the reflectance map. Note that the decompositions of normal-light images do not participate in the Enhance-Net training stage. \relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig: Decom-Net}{{5}{6}{The proposed Decom-Net architecture. The Decom-Net decomposes the input image into reflectance and illumination and can suppress the noise in the reflectance map. Note that the decompositions of normal-light images do not participate in the Enhance-Net training stage. \relax }{figure.caption.5}{}}
\bibstyle{unsrt}
\bibdata{reference}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces   The proposed Enhance-Net architecture. The Enhance-Net takes the output of Decom-Net as the input to enhance the contrast and brightness of the illumination. \relax }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{fig: Enhance-Net}{{6}{7}{The proposed Enhance-Net architecture. The Enhance-Net takes the output of Decom-Net as the input to enhance the contrast and brightness of the illumination. \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.4}Future}{7}{subsubsection.1.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}(2023.1)LightingNet: An Integrated Learning Method for Low-Light Image Enhancement}{7}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{LightingNet：一种用于弱光图像增强的集成学习方法}{7}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(IEEE Transactions on Computational Imaging 二区) doi: 10.1109/TCI.2023.3240087}{7}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Research Background}{7}{subsubsection.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2}Contribution}{7}{subsubsection.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.3}Approach}{7}{subsubsection.1.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.4}Future}{8}{subsubsection.1.4.4}\protected@file@percent }
\newlabel{LastPage}{{}{8}{}{page.8}{}}
\xdef\lastpage@lastpage{8}
\xdef\lastpage@lastpageHy{8}
\gdef \@abspage@last{8}
