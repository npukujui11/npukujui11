\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\citation{ueng1995gamma}
\citation{stark2000adaptive}
\citation{land1971lightness}
\citation{liu2021benchmarking}
\citation{dai2019fractional}
\citation{ma2019improved}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}研究介绍}{3}{part.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}研究意义}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}研究背景和现状}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}传统低照度图像增强方法}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}基于 Retinex 的方法}{3}{subsubsection.2.1.1}\protected@file@percent }
\citation{cooper2004analysis}
\citation{202013}
\citation{cooper2004analysis}
\citation{cooper2004analysis}
\citation{stark2000adaptive}
\newlabel{eq: Retinex model formula}{{2.1}{4}{基于 Retinex 的方法}{equation.2.1}{}}
\newlabel{eq: Retinex model formula log}{{2.2}{4}{基于 Retinex 的方法}{equation.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces   Retinex 算法处理过程 \relax }}{4}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: Retinex model}{{1}{4}{Retinex 算法处理过程 \relax }{figure.caption.1}{}}
\newlabel{fig: Retinex Model_input}{{2a}{4}{低照度图像\relax }{figure.caption.2}{}}
\newlabel{sub@fig: Retinex Model_input}{{a}{4}{低照度图像\relax }{figure.caption.2}{}}
\newlabel{fig: Retinex Model_Retinex}{{2b}{4}{Retinex\cite {cooper2004analysis}\relax }{figure.caption.2}{}}
\newlabel{sub@fig: Retinex Model_Retinex}{{b}{4}{Retinex\cite {cooper2004analysis}\relax }{figure.caption.2}{}}
\newlabel{fig: Retinex Model_SSR}{{2c}{4}{SSR\relax }{figure.caption.2}{}}
\newlabel{sub@fig: Retinex Model_SSR}{{c}{4}{SSR\relax }{figure.caption.2}{}}
\newlabel{fig: Retinex Model_MSR}{{2d}{4}{MSR\relax }{figure.caption.2}{}}
\newlabel{sub@fig: Retinex Model_MSR}{{d}{4}{MSR\relax }{figure.caption.2}{}}
\newlabel{fig: Retinex Model_MSRCR}{{2e}{4}{MSRCR\relax }{figure.caption.2}{}}
\newlabel{sub@fig: Retinex Model_MSRCR}{{e}{4}{MSRCR\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces   传统 Retinex 算法实验结果。 \relax }}{4}{figure.caption.2}\protected@file@percent }
\newlabel{fig: Retinex Model}{{2}{4}{传统 Retinex 算法实验结果。 \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}基于直方图的方法}{5}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces   直方图均衡化示意图 \relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig: Histogram equalization}{{3}{5}{直方图均衡化示意图 \relax }{figure.caption.3}{}}
\newlabel{eq: Histogram}{{2.3}{5}{基于直方图的方法}{equation.2.3}{}}
\citation{dong2010fast}
\citation{lore2017llnet}
\newlabel{eq: HE}{{2.4}{6}{基于直方图的方法}{equation.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}基于图像反相的方法}{6}{subsubsection.2.1.3}\protected@file@percent }
\newlabel{fig: LL input}{{\caption@xref {fig: LL input}{ on input line 238}}{6}{基于图像反相的方法}{figure.caption.4}{}}
\newlabel{sub@fig: LL input}{{}{6}{基于图像反相的方法}{figure.caption.4}{}}
\newlabel{fig: Inversed}{{\caption@xref {fig: Inversed}{ on input line 243}}{6}{基于图像反相的方法}{figure.caption.4}{}}
\newlabel{sub@fig: Inversed}{{}{6}{基于图像反相的方法}{figure.caption.4}{}}
\newlabel{fig: marked image}{{\caption@xref {fig: marked image}{ on input line 248}}{6}{基于图像反相的方法}{figure.caption.4}{}}
\newlabel{sub@fig: marked image}{{}{6}{基于图像反相的方法}{figure.caption.4}{}}
\newlabel{fig: de-haze}{{\caption@xref {fig: de-haze}{ on input line 253}}{6}{基于图像反相的方法}{figure.caption.4}{}}
\newlabel{sub@fig: de-haze}{{}{6}{基于图像反相的方法}{figure.caption.4}{}}
\newlabel{fig: Final output}{{\caption@xref {fig: Final output}{ on input line 258}}{6}{基于图像反相的方法}{figure.caption.4}{}}
\newlabel{sub@fig: Final output}{{}{6}{基于图像反相的方法}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces   (a) 低照度图片输入 I. (b) 从输入I获得的反向图片 R.(c) 标记图像：在至少一种颜色（RGB）通道中具有低强度的像素为绿色。 (d) 去雾： 使用公式获得输出 J. (e) 最终得输出结果 E. \relax }}{6}{figure.caption.4}\protected@file@percent }
\newlabel{fig: Image Inverse}{{4}{6}{(a) 低照度图片输入 I. (b) 从输入I获得的反向图片 R.(c) 标记图像：在至少一种颜色（RGB）通道中具有低强度的像素为绿色。 (d) 去雾： 使用公式获得输出 J. (e) 最终得输出结果 E. \relax }{figure.caption.4}{}}
\newlabel{eq: Image Reverse}{{2.5}{6}{基于图像反相的方法}{equation.2.5}{}}
\citation{tang2023low}
\citation{lore2017llnet}
\citation{lv2018mbllen}
\citation{wang2018gladnet}
\citation{lu2020tbefn}
\citation{li2021low}
\citation{ravirathinam2021c}
\citation{lim2020dslr}
\citation{wei2018deep}
\citation{shen2017msr}
\citation{zhang2019kindling}
\citation{cui2022illumination}
\citation{carion2020end}
\citation{wang2023ultra}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}基于深度学习的低照度图像增强方法}{7}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}有监督学习}{7}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{端到端 (End-to-end) 方法}{7}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Retinex 理论方法}{7}{subsubsection.2.2.1}\protected@file@percent }
\citation{jiang2021enlightengan}
\citation{fu2022gan}
\citation{ni2020towards}
\citation{zhang2021unsupervised}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces   RetinexNet算法结构图。主要由三个部分组成，分解(Decomposition)，调节(Adjustment)和重构(Reconstruction)。 \relax }}{8}{figure.caption.5}\protected@file@percent }
\newlabel{fig: RetinexNet}{{5}{8}{RetinexNet算法结构图。主要由三个部分组成，分解(Decomposition)，调节(Adjustment)和重构(Reconstruction)。 \relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {paragraph}{基于 Transformer 的方法}{8}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}无监督学习}{8}{subsubsection.2.2.2}\protected@file@percent }
\citation{qiao2021deep}
\citation{robert2018hybridnet}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces   EnlightenGAN 结构图 \relax }}{9}{figure.caption.6}\protected@file@percent }
\newlabel{fig: EnlightenGAN}{{6}{9}{EnlightenGAN 结构图 \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}半监督学习}{9}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces   DRBN 结构图 \relax }}{9}{figure.caption.7}\protected@file@percent }
\newlabel{fig: DRBN}{{7}{9}{DRBN 结构图 \relax }{figure.caption.7}{}}
\citation{woo2018cbam}
\citation{ramachandran2019stand}
\citation{woo2018cbam}
\citation{li2023scconv}
\citation{chen2018learning}
\citation{chen2018learning,zamir2021learning}
\citation{chen2018learning}
\citation{chen2018learning,zamir2021learning}
\citation{meng2020gia}
\citation{chen2018learning,zamir2021learning}
\citation{meng2020gia}
\citation{chen2018learning,meng2020gia,zamir2021learning}
\citation{zhou2018unet++,zhou2019unet++}
\citation{yang2021locally,zhang2020attention}
\citation{li2018multi,zamir2020learning}
\citation{li2020visual}
\citation{xu2020learning}
\@writefile{toc}{\contentsline {paragraph}{Attention in CV}{10}{figure.caption.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{U-Net for LLIE}{10}{figure.caption.7}\protected@file@percent }
\citation{zhu2020eemefn}
\citation{zhu2020eemefn}
\@writefile{toc}{\contentsline {paragraph}{CNN for LLIE}{11}{figure.caption.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}方向}{11}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces   该 LLIE 结构源自\cite  {zhu2020eemefn},如其 Multi-Exposure Fusion部分采用多曝光融合结构,与由 Initial image 生成的边缘图进行 Concat,后续通过一个 U-Net 网络进一步恢复图像。 \relax }}{11}{figure.caption.8}\protected@file@percent }
\newlabel{fig: EEMEFN}{{8}{11}{该 LLIE 结构源自\cite {zhu2020eemefn},如其 Multi-Exposure Fusion部分采用多曝光融合结构,与由 Initial image 生成的边缘图进行 Concat,后续通过一个 U-Net 网络进一步恢复图像。 \relax }{figure.caption.8}{}}
\citation{wang2022uformer}
\citation{peng2021conformer}
\citation{peng2021conformer}
\citation{wang2022uformer}
\citation{li2023effective}
\citation{li2023effective}
\citation{xu2023low}
\citation{zhu2020eemefn}
\citation{rana2021edge}
\bibstyle{unsrt}
\bibdata{reference}
\bibcite{ueng1995gamma}{1}
\bibcite{stark2000adaptive}{2}
\bibcite{land1971lightness}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}方向一}{12}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}方向二}{12}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces   Low-Lighting 图像恢复网络。结构受 Conformer\cite  {peng2021conformer} （见 Fig. \ref {fig: Conformer architecture}）启发，将原来结构中 CNN 分支的 ResNet 结构修改为 U-Net 结构。其采用一个 U-Net 和 ViT 的并行架构，通过 U-Net 结构得到一个弱恢复的弱特征图 $\mathcal  {F}_2$，通过 ViT 融合的特征可以初步增强弱特征图 $\mathcal  {F}_2$，ViT 的输出经过 Patch Expanding 的特征图 $\mathcal  {F}_3$ 经过与 U-Net 输出的特征图 $\mathcal  {F}_2$ 融合之后得到一个初步恢复的图片 output image，用以后续参与图片的进一步恢复。 \relax }}{13}{figure.caption.9}\protected@file@percent }
\newlabel{fig: The proposed architecture}{{9}{13}{Low-Lighting 图像恢复网络。结构受 Conformer\cite {peng2021conformer} （见 Fig. \ref {fig: Conformer architecture}）启发，将原来结构中 CNN 分支的 ResNet 结构修改为 U-Net 结构。其采用一个 U-Net 和 ViT 的并行架构，通过 U-Net 结构得到一个弱恢复的弱特征图 $\mathcal {F}_2$，通过 ViT 融合的特征可以初步增强弱特征图 $\mathcal {F}_2$，ViT 的输出经过 Patch Expanding 的特征图 $\mathcal {F}_3$ 经过与 U-Net 输出的特征图 $\mathcal {F}_2$ 融合之后得到一个初步恢复的图片 output image，用以后续参与图片的进一步恢复。 \relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces   Uformer 的结构。 \relax }}{13}{figure.caption.10}\protected@file@percent }
\newlabel{fig: Uformer}{{10}{13}{Uformer 的结构。 \relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces   MCLNet 的结构 \relax }}{14}{figure.caption.11}\protected@file@percent }
\newlabel{fig: MCLNet}{{11}{14}{MCLNet 的结构 \relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces   该结构的边缘图直接从 $I$ 中通过 StyleGAN 得到边缘图 $I_s$, 而非从 $I_{\alpha }$ 中通过边缘网络获取边缘图。 \relax }}{14}{figure.caption.12}\protected@file@percent }
\newlabel{fig: Overview}{{12}{14}{该结构的边缘图直接从 $I$ 中通过 StyleGAN 得到边缘图 $I_s$, 而非从 $I_{\alpha }$ 中通过边缘网络获取边缘图。 \relax }{figure.caption.12}{}}
\bibcite{liu2021benchmarking}{4}
\bibcite{dai2019fractional}{5}
\bibcite{ma2019improved}{6}
\bibcite{cooper2004analysis}{7}
\bibcite{202013}{8}
\bibcite{dong2010fast}{9}
\bibcite{lore2017llnet}{10}
\bibcite{tang2023low}{11}
\bibcite{lv2018mbllen}{12}
\bibcite{wang2018gladnet}{13}
\bibcite{lu2020tbefn}{14}
\bibcite{li2021low}{15}
\bibcite{ravirathinam2021c}{16}
\bibcite{lim2020dslr}{17}
\bibcite{wei2018deep}{18}
\bibcite{shen2017msr}{19}
\bibcite{zhang2019kindling}{20}
\bibcite{cui2022illumination}{21}
\bibcite{carion2020end}{22}
\bibcite{wang2023ultra}{23}
\bibcite{jiang2021enlightengan}{24}
\bibcite{fu2022gan}{25}
\bibcite{ni2020towards}{26}
\bibcite{zhang2021unsupervised}{27}
\bibcite{qiao2021deep}{28}
\bibcite{robert2018hybridnet}{29}
\bibcite{woo2018cbam}{30}
\bibcite{ramachandran2019stand}{31}
\bibcite{li2023scconv}{32}
\bibcite{chen2018learning}{33}
\bibcite{zamir2021learning}{34}
\bibcite{meng2020gia}{35}
\bibcite{zhou2018unet++}{36}
\bibcite{zhou2019unet++}{37}
\bibcite{yang2021locally}{38}
\bibcite{zhang2020attention}{39}
\bibcite{li2018multi}{40}
\bibcite{zamir2020learning}{41}
\bibcite{li2020visual}{42}
\bibcite{xu2020learning}{43}
\bibcite{zhu2020eemefn}{44}
\bibcite{wang2022uformer}{45}
\bibcite{peng2021conformer}{46}
\bibcite{li2023effective}{47}
\bibcite{xu2023low}{48}
\bibcite{rana2021edge}{49}
\newlabel{LastPage}{{}{18}{}{page.18}{}}
\xdef\lastpage@lastpage{18}
\xdef\lastpage@lastpageHy{18}
\gdef \@abspage@last{18}
