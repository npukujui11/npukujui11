\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\citation{liu2021retinex,xu2020learning}
\citation{ueng1995gamma}
\citation{stark2000adaptive}
\citation{land1971lightness}
\citation{liu2021benchmarking}
\citation{dai2019fractional}
\citation{ma2019improved}
\citation{cooper2004analysis}
\citation{stark2000adaptive}
\citation{dong2010fast}
\citation{lore2017llnet}
\citation{lv2018mbllen}
\citation{wang2018gladnet}
\citation{lu2020tbefn}
\citation{li2021low}
\citation{ravirathinam2021c}
\citation{wei2018deep}
\citation{shen2017msr}
\citation{jiang2021enlightengan}
\citation{fu2022gan}
\citation{zhang2021unsupervised}
\citation{qiao2021deep}
\citation{robert2018hybridnet}
\citation{zhu2020zero}
\citation{zhang2019zero}
\@writefile{toc}{\contentsline {section}{\numberline {1}立题依据}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}课题的研究意义}{3}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}国内外研究现状分析}{3}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}传统弱光图像增强方法}{3}{subsubsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}基于深度学习的弱光图像增强方法}{3}{subsubsection.1.2.2}\protected@file@percent }
\citation{dosovitskiy2020image}
\citation{cui2022illumination}
\citation{carion2020end}
\citation{wang2023ultra}
\bibstyle{unsrt}
\bibdata{reference}
\bibcite{liu2021retinex}{1}
\bibcite{xu2020learning}{2}
\bibcite{ueng1995gamma}{3}
\bibcite{stark2000adaptive}{4}
\bibcite{land1971lightness}{5}
\bibcite{liu2021benchmarking}{6}
\bibcite{dai2019fractional}{7}
\bibcite{ma2019improved}{8}
\bibcite{cooper2004analysis}{9}
\bibcite{202013}{10}
\bibcite{dong2010fast}{11}
\bibcite{lore2017llnet}{12}
\bibcite{tang2023low}{13}
\bibcite{lv2018mbllen}{14}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}主要的参考文献}{4}{subsection.1.3}\protected@file@percent }
\bibcite{wang2018gladnet}{15}
\bibcite{lu2020tbefn}{16}
\bibcite{li2021low}{17}
\bibcite{ravirathinam2021c}{18}
\bibcite{lim2020dslr}{19}
\bibcite{wei2018deep}{20}
\bibcite{shen2017msr}{21}
\bibcite{zhang2019kindling}{22}
\bibcite{cui2022illumination}{23}
\bibcite{carion2020end}{24}
\bibcite{wang2023ultra}{25}
\bibcite{jiang2021enlightengan}{26}
\bibcite{fu2022gan}{27}
\bibcite{ni2020towards}{28}
\bibcite{zhang2021unsupervised}{29}
\bibcite{qiao2021deep}{30}
\bibcite{robert2018hybridnet}{31}
\bibcite{zhu2020zero}{32}
\bibcite{zhang2019zero}{33}
\bibcite{cai2018learning}{34}
\bibcite{guo2016lime}{35}
\bibcite{singh2016contrast}{36}
\bibcite{chai2014root}{37}
\bibcite{kellman2005image}{38}
\bibcite{yu2017low}{39}
\bibcite{zhang2018unreasonable}{40}
\bibcite{sheikh2005information}{41}
\bibcite{russakovsky2015imagenet}{42}
\bibcite{ignatov2018wespe}{43}
\bibcite{zhu2015low}{44}
\bibcite{mittal2012making}{45}
\bibcite{fu2016weighted}{46}
\bibcite{ma2017learning}{47}
\bibcite{ke2021musiq}{48}
\bibcite{talebi2018nima}{49}
\bibcite{fang2020perceptual}{50}
\bibcite{yang2021locally}{51}
\bibcite{zhang2020attention}{52}
\bibcite{li2018multi}{53}
\bibcite{zamir2020learning}{54}
\bibcite{li2020visual}{55}
\bibcite{xu2023low}{56}
\bibcite{zhu2020eemefn}{57}
\bibcite{rana2021edge}{58}
\bibcite{chen2018learning}{59}
\bibcite{wang2004image}{60}
\bibcite{pietikainen2010local}{61}
\bibcite{woo2018cbam}{62}
\bibcite{ramachandran2019stand}{63}
\bibcite{li2023scconv}{64}
\bibcite{zamir2021learning}{65}
\bibcite{meng2020gia}{66}
\bibcite{zhou2018unet++}{67}
\bibcite{zhou2019unet++}{68}
\bibcite{vaswani2017attention}{69}
\bibcite{dosovitskiy2020image}{70}
\bibcite{wang2022ultrahighdefinition}{71}
\bibcite{wang2021uformer}{72}
\bibcite{chen2023cross}{73}
\bibcite{burt1984pyramid}{74}
\bibcite{wang2022uformer}{75}
\bibcite{peng2021conformer}{76}
\bibcite{jain1991unsupervised}{77}
\bibcite{lowe2004distinctive}{78}
\bibcite{ojala2002multiresolution}{79}
\bibcite{lisin2005combining}{80}
\bibcite{karu1996there}{81}
\bibcite{szegedy2016rethinking}{82}
\bibcite{huber1992robust}{83}
\bibcite{johnson2016perceptual}{84}
\bibcite{liu2017richer}{85}
\bibcite{xie2015holistically}{86}
\bibcite{simonyan2014very}{87}
\bibcite{maini2009study}{88}
\bibcite{pisano1998contrast}{89}
\bibcite{li2018lightennet}{90}
\bibcite{guo2020zero}{91}
\citation{liu2021benchmarking}
\citation{yang2021locally,zhang2020attention}
\citation{li2018multi,zamir2020learning}
\citation{li2020visual}
\citation{xu2023low}
\citation{zhu2020eemefn}
\citation{zhu2020eemefn}
\citation{rana2021edge}
\citation{rana2021edge}
\@writefile{toc}{\contentsline {section}{\numberline {2}研究方案}{10}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}研究目标}{10}{subsection.2.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: input}{{\caption@xref {fig: input}{ on input line 157}}{10}{研究目标}{figure.caption.1}{}}
\newlabel{sub@fig: input}{{}{10}{研究目标}{figure.caption.1}{}}
\newlabel{fig: LLNet_VE_LOL}{{\caption@xref {fig: LLNet_VE_LOL}{ on input line 163}}{10}{研究目标}{figure.caption.1}{}}
\newlabel{sub@fig: LLNet_VE_LOL}{{}{10}{研究目标}{figure.caption.1}{}}
\newlabel{fig: RetinexNet_VE_LOL}{{\caption@xref {fig: RetinexNet_VE_LOL}{ on input line 169}}{10}{研究目标}{figure.caption.1}{}}
\newlabel{sub@fig: RetinexNet_VE_LOL}{{}{10}{研究目标}{figure.caption.1}{}}
\newlabel{fig: MBLLEN_LOL}{{\caption@xref {fig: MBLLEN_LOL}{ on input line 175}}{10}{研究目标}{figure.caption.1}{}}
\newlabel{sub@fig: MBLLEN_LOL}{{}{10}{研究目标}{figure.caption.1}{}}
\newlabel{fig: EnlightenGAN_VE_LOL}{{\caption@xref {fig: EnlightenGAN_VE_LOL}{ on input line 181}}{10}{研究目标}{figure.caption.1}{}}
\newlabel{sub@fig: EnlightenGAN_VE_LOL}{{}{10}{研究目标}{figure.caption.1}{}}
\newlabel{fig: RRDNet_VE_LOL}{{\caption@xref {fig: RRDNet_VE_LOL}{ on input line 187}}{10}{研究目标}{figure.caption.1}{}}
\newlabel{sub@fig: RRDNet_VE_LOL}{{}{10}{研究目标}{figure.caption.1}{}}
\newlabel{fig: DRBN_VE_LOL}{{\caption@xref {fig: DRBN_VE_LOL}{ on input line 193}}{10}{研究目标}{figure.caption.1}{}}
\newlabel{sub@fig: DRBN_VE_LOL}{{}{10}{研究目标}{figure.caption.1}{}}
\newlabel{fig: Zero-DCE++}{{\caption@xref {fig: Zero-DCE++}{ on input line 199}}{10}{研究目标}{figure.caption.1}{}}
\newlabel{sub@fig: Zero-DCE++}{{}{10}{研究目标}{figure.caption.1}{}}
\newlabel{fig: KinD++}{{\caption@xref {fig: KinD++}{ on input line 205}}{10}{研究目标}{figure.caption.1}{}}
\newlabel{sub@fig: KinD++}{{}{10}{研究目标}{figure.caption.1}{}}
\newlabel{fig: URetinexNet}{{\caption@xref {fig: URetinexNet}{ on input line 211}}{10}{研究目标}{figure.caption.1}{}}
\newlabel{sub@fig: URetinexNet}{{}{10}{研究目标}{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces   不同算法对从 VE-LOL-L 数据集采样的弱光图像的可视化结果。 \relax }}{10}{figure.caption.1}\protected@file@percent }
\newlabel{fig: VE-LOL-L Visual}{{1}{10}{不同算法对从 VE-LOL-L 数据集采样的弱光图像的可视化结果。 \relax }{figure.caption.1}{}}
\citation{chen2018learning}
\citation{xu2023low}
\citation{wang2004image}
\citation{chen2018learning}
\citation{xu2023low}
\citation{wang2004image}
\citation{zhu2020eemefn,rana2021edge}
\newlabel{fig: EEMEFN}{{2a}{11}{该 LLIE 结构源自\cite {zhu2020eemefn},如其 Multi-Exposure Fusion 部分采用多曝光融合结构,与由 Initial image 生成的边缘图进行 Concat, 后续通过一个 U-Net 网络进一步恢复图像。\relax }{figure.caption.2}{}}
\newlabel{sub@fig: EEMEFN}{{a}{11}{该 LLIE 结构源自\cite {zhu2020eemefn},如其 Multi-Exposure Fusion 部分采用多曝光融合结构,与由 Initial image 生成的边缘图进行 Concat, 后续通过一个 U-Net 网络进一步恢复图像。\relax }{figure.caption.2}{}}
\newlabel{fig: EdgeNet}{{2b}{11}{该 LLIE 结构源自\cite {rana2021edge}使用 EdgeNet 首先从低光图像中过滤边缘，EnhanceNet 反复使用上采样和下采样块的组合，从局部到全局逐渐提取特征，并消除伪影和噪声。\relax }{figure.caption.2}{}}
\newlabel{sub@fig: EdgeNet}{{b}{11}{该 LLIE 结构源自\cite {rana2021edge}使用 EdgeNet 首先从低光图像中过滤边缘，EnhanceNet 反复使用上采样和下采样块的组合，从局部到全局逐渐提取特征，并消除伪影和噪声。\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces   边缘图像指导弱光图像增强的传统架构。 \relax }}{11}{figure.caption.2}\protected@file@percent }
\newlabel{fig: Traditional Architecture}{{2}{11}{边缘图像指导弱光图像增强的传统架构。 \relax }{figure.caption.2}{}}
\newlabel{fig: Input}{{3a}{11}{Input\relax }{figure.caption.3}{}}
\newlabel{sub@fig: Input}{{a}{11}{Input\relax }{figure.caption.3}{}}
\newlabel{fig: Structure of (a)}{{3b}{11}{Structure of (a)\relax }{figure.caption.3}{}}
\newlabel{sub@fig: Structure of (a)}{{b}{11}{Structure of (a)\relax }{figure.caption.3}{}}
\newlabel{fig: SNR (CVPR 2022)}{{3c}{11}{SNR (CVPR 2022)\relax }{figure.caption.3}{}}
\newlabel{sub@fig: SNR (CVPR 2022)}{{c}{11}{SNR (CVPR 2022)\relax }{figure.caption.3}{}}
\newlabel{fig: Structure Modeling}{{3d}{11}{Structure Modeling\relax }{figure.caption.3}{}}
\newlabel{sub@fig: Structure Modeling}{{d}{11}{Structure Modeling\relax }{figure.caption.3}{}}
\newlabel{fig: SMG-LLIE}{{3e}{11}{SMG-LLIE\relax }{figure.caption.3}{}}
\newlabel{sub@fig: SMG-LLIE}{{e}{11}{SMG-LLIE\relax }{figure.caption.3}{}}
\newlabel{fig: Ground Truth}{{3f}{11}{Ground Truth\relax }{figure.caption.3}{}}
\newlabel{sub@fig: Ground Truth}{{f}{11}{Ground Truth\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces   SID-sRGB\cite  {chen2018learning}中一张弱光图片, 通过SOTA方法 (c) 和\cite  {xu2023low}提出的方法 (e)增强。作者的方法可以从输入的图像中合成结构图(d)，使细节更清晰，对比度更清晰，颜色更鲜艳。虽然(c)的 PSNR 为 28.17，但其 SSIM 低为 0.75。作者的方法在dB和SSIM\cite  {wang2004image}的得分都很高，分别为28.60 dB 和 0.80。 \relax }}{11}{figure.caption.3}\protected@file@percent }
\newlabel{fig: Structural Information}{{3}{11}{SID-sRGB\cite {chen2018learning}中一张弱光图片, 通过SOTA方法 (c) 和\cite {xu2023low}提出的方法 (e)增强。作者的方法可以从输入的图像中合成结构图(d)，使细节更清晰，对比度更清晰，颜色更鲜艳。虽然(c)的 PSNR 为 28.17，但其 SSIM 低为 0.75。作者的方法在dB和SSIM\cite {wang2004image}的得分都很高，分别为28.60 dB 和 0.80。 \relax }{figure.caption.3}{}}
\citation{xu2023low}
\citation{pietikainen2010local}
\citation{woo2018cbam}
\citation{ramachandran2019stand}
\citation{woo2018cbam}
\citation{chen2018learning}
\citation{zhou2018unet++,zhou2019unet++}
\citation{meng2020gia}
\citation{xu2020learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}研究内容}{12}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}拟解决的关键问题}{12}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}拟采取的研究方法}{12}{subsection.2.4}\protected@file@percent }
\citation{vaswani2017attention}
\citation{dosovitskiy2020image}
\citation{chen2023cross}
\citation{burt1984pyramid}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}技术路线}{13}{subsection.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces   我们提出的技术框架。 \relax }}{13}{figure.caption.4}\protected@file@percent }
\newlabel{fig: Total Architecture}{{4}{13}{我们提出的技术框架。 \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}方案及可行性研究}{13}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}初步恢复图像的生成模型}{13}{subsubsection.2.6.1}\protected@file@percent }
\citation{wang2022uformer}
\citation{peng2021conformer}
\citation{peng2021conformer}
\citation{jain1991unsupervised,lowe2004distinctive,ojala2002multiresolution}
\citation{lisin2005combining}
\newlabel{fig: First Architecture}{{5a}{14}{Parallel Architecture\relax }{figure.caption.5}{}}
\newlabel{sub@fig: First Architecture}{{a}{14}{Parallel Architecture\relax }{figure.caption.5}{}}
\newlabel{fig: Up-sampling and down-sampling}{{5b}{14}{Up-sampling and Down-sampling\relax }{figure.caption.5}{}}
\newlabel{sub@fig: Up-sampling and down-sampling}{{b}{14}{Up-sampling and Down-sampling\relax }{figure.caption.5}{}}
\newlabel{fig: The proposed initial architecture(Abstract Picture)}{{5c}{14}{Thumbnail of PACUT\relax }{figure.caption.5}{}}
\newlabel{sub@fig: The proposed initial architecture(Abstract Picture)}{{c}{14}{Thumbnail of PACUT\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces   我们提出的初步恢复图架构。图\ref {fig: First Architecture} CNN 分支和 Transformer 分支以及 FCU (Feature Coupling Unit)。图\ref {fig: Up-sampling and down-sampling} 特征映射和 Patch embeddings 空间对齐的上采样和下采样过程。 图\ref {fig: The proposed initial architecture(Abstract Picture)} PACUT 的缩略图。PACUT 结构受 Conformer\cite  {peng2021conformer}启发，将原来结构中 CNN 分支的 ResNet 结构修改为 U-Net 结构。其采用一个 U-Net 和 ViT 的并行架构，通过 U-Net 结构得到一个弱恢复的弱特征图 $\mathcal  {F}_2$，通过 ViT 融合的特征可以初步增强弱特征图 $\mathcal  {F}_2$，ViT 的输出经过 Patch Expanding 的特征图 $\mathcal  {F}_3$ 经过与 U-Net 输出的特征图 $\mathcal  {F}_2$ 融合之后得到一个初步恢复的图片 output image，用以后续参与图片的进一步恢复。 \relax }}{14}{figure.caption.5}\protected@file@percent }
\newlabel{fig: PACUT}{{5}{14}{我们提出的初步恢复图架构。图\ref {fig: First Architecture} CNN 分支和 Transformer 分支以及 FCU (Feature Coupling Unit)。图\ref {fig: Up-sampling and down-sampling} 特征映射和 Patch embeddings 空间对齐的上采样和下采样过程。 图\ref {fig: The proposed initial architecture(Abstract Picture)} PACUT 的缩略图。PACUT 结构受 Conformer\cite {peng2021conformer}启发，将原来结构中 CNN 分支的 ResNet 结构修改为 U-Net 结构。其采用一个 U-Net 和 ViT 的并行架构，通过 U-Net 结构得到一个弱恢复的弱特征图 $\mathcal {F}_2$，通过 ViT 融合的特征可以初步增强弱特征图 $\mathcal {F}_2$，ViT 的输出经过 Patch Expanding 的特征图 $\mathcal {F}_3$ 经过与 U-Net 输出的特征图 $\mathcal {F}_2$ 融合之后得到一个初步恢复的图片 output image，用以后续参与图片的进一步恢复。 \relax }{figure.caption.5}{}}
\citation{peng2021conformer}
\citation{karu1996there}
\citation{szegedy2016rethinking}
\citation{liu2017richer}
\citation{xie2015holistically}
\citation{maini2009study}
\citation{liu2017richer}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2}边缘检测网络}{15}{subsubsection.2.6.2}\protected@file@percent }
\newlabel{fig: LLI}{{6a}{15}{LLI\relax }{figure.caption.6}{}}
\newlabel{sub@fig: LLI}{{a}{15}{LLI\relax }{figure.caption.6}{}}
\newlabel{fig: LLI_canny}{{6b}{15}{LLI Canny\relax }{figure.caption.6}{}}
\newlabel{sub@fig: LLI_canny}{{b}{15}{LLI Canny\relax }{figure.caption.6}{}}
\newlabel{fig: LLI_rcf}{{6c}{15}{LLI RCF\relax }{figure.caption.6}{}}
\newlabel{sub@fig: LLI_rcf}{{c}{15}{LLI RCF\relax }{figure.caption.6}{}}
\newlabel{fig: LLI_hog}{{6d}{15}{LLI HOG\relax }{figure.caption.6}{}}
\newlabel{sub@fig: LLI_hog}{{d}{15}{LLI HOG\relax }{figure.caption.6}{}}
\newlabel{fig: LLI_lbp}{{6e}{15}{LLI LBP\relax }{figure.caption.6}{}}
\newlabel{sub@fig: LLI_lbp}{{e}{15}{LLI LBP\relax }{figure.caption.6}{}}
\newlabel{fig: GI}{{6f}{15}{GT\relax }{figure.caption.6}{}}
\newlabel{sub@fig: GI}{{f}{15}{GT\relax }{figure.caption.6}{}}
\newlabel{fig: GT_canny}{{6g}{15}{GT Canny\relax }{figure.caption.6}{}}
\newlabel{sub@fig: GT_canny}{{g}{15}{GT Canny\relax }{figure.caption.6}{}}
\newlabel{fig: GT_rcf}{{6h}{15}{GT RCF\relax }{figure.caption.6}{}}
\newlabel{sub@fig: GT_rcf}{{h}{15}{GT RCF\relax }{figure.caption.6}{}}
\newlabel{fig: GT_hog}{{6i}{15}{GT HOG\relax }{figure.caption.6}{}}
\newlabel{sub@fig: GT_hog}{{i}{15}{GT HOG\relax }{figure.caption.6}{}}
\newlabel{fig: GT_lbp}{{6j}{15}{GT LBP\relax }{figure.caption.6}{}}
\newlabel{sub@fig: GT_lbp}{{j}{15}{GT LBP\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces   基于 LOL-v2 弱光数据集的边缘信息。 \relax }}{15}{figure.caption.6}\protected@file@percent }
\newlabel{fig: LLI Structure Information}{{6}{15}{基于 LOL-v2 弱光数据集的边缘信息。 \relax }{figure.caption.6}{}}
\citation{maini2009study}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces   边缘检测网络。 \relax }}{16}{figure.caption.7}\protected@file@percent }
\newlabel{fig: Edge Detection Network}{{7}{16}{边缘检测网络。 \relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}计划进度}{16}{subsection.2.7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces   计划进度 \relax }}{16}{table.caption.8}\protected@file@percent }
\newlabel{tab: Schedule}{{1}{16}{计划进度 \relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}预期的研究进展}{16}{subsection.2.8}\protected@file@percent }
\citation{wei2018deep}
\citation{cai2018learning}
\citation{wang2004image}
\citation{wang2004image}
\citation{mittal2012making}
\citation{pisano1998contrast}
\citation{li2018lightennet}
\citation{lore2017llnet}
\citation{wei2018deep}
\citation{lv2018mbllen}
\citation{jiang2021enlightengan}
\citation{guo2020zero}
\citation{zhang2019kindling}
\citation{wei2018deep}
\citation{cai2018learning}
\citation{pisano1998contrast}
\citation{li2018lightennet}
\citation{lore2017llnet}
\citation{wei2018deep}
\citation{zhang2019kindling}
\citation{lv2018mbllen}
\citation{jiang2021enlightengan}
\citation{guo2020zero}
\@writefile{toc}{\contentsline {section}{\numberline {3}课题的创新性}{17}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}研究基础}{17}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}已完成工作}{17}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}初步恢复图像的生成模型实验结果}{17}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}数据集和评价指标}{17}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}对比试验}{17}{subsubsection.4.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces   LOL和SCIE数据集在各方法下的对比值，其中红色表示最优，蓝色表示次优，$↑$表示越高越好，$↓$表示越低越好。 \relax }}{18}{table.caption.9}\protected@file@percent }
\newlabel{tab: Quantitative Comparisons on LOL-test and SCI testing datasets}{{2}{18}{LOL和SCIE数据集在各方法下的对比值，其中红色表示最优，蓝色表示次优，$↑$表示越高越好，$↓$表示越低越好。 \relax }{table.caption.9}{}}
\newlabel{fig: LLI Input}{{8a}{18}{Input\relax }{figure.caption.10}{}}
\newlabel{sub@fig: LLI Input}{{a}{18}{Input\relax }{figure.caption.10}{}}
\newlabel{fig: LightenNet}{{8b}{18}{LightenNet\relax }{figure.caption.10}{}}
\newlabel{sub@fig: LightenNet}{{b}{18}{LightenNet\relax }{figure.caption.10}{}}
\newlabel{fig: LLI LLNet}{{8c}{18}{LLNet\relax }{figure.caption.10}{}}
\newlabel{sub@fig: LLI LLNet}{{c}{18}{LLNet\relax }{figure.caption.10}{}}
\newlabel{fig: LLI RetinexNet}{{8d}{18}{RetinexNet\relax }{figure.caption.10}{}}
\newlabel{sub@fig: LLI RetinexNet}{{d}{18}{RetinexNet\relax }{figure.caption.10}{}}
\newlabel{fig: KinD}{{8e}{18}{KinD\relax }{figure.caption.10}{}}
\newlabel{sub@fig: KinD}{{e}{18}{KinD\relax }{figure.caption.10}{}}
\newlabel{fig: MBLLEN}{{8f}{18}{MBLLEN\relax }{figure.caption.10}{}}
\newlabel{sub@fig: MBLLEN}{{f}{18}{MBLLEN\relax }{figure.caption.10}{}}
\newlabel{fig: LLI EnlightenGAN}{{8g}{18}{EnlightenGAN\relax }{figure.caption.10}{}}
\newlabel{sub@fig: LLI EnlightenGAN}{{g}{18}{EnlightenGAN\relax }{figure.caption.10}{}}
\newlabel{fig: Zero-DCE}{{8h}{18}{Zero-DCE\relax }{figure.caption.10}{}}
\newlabel{sub@fig: Zero-DCE}{{h}{18}{Zero-DCE\relax }{figure.caption.10}{}}
\newlabel{fig: Ours}{{8i}{18}{Ours\relax }{figure.caption.10}{}}
\newlabel{sub@fig: Ours}{{i}{18}{Ours\relax }{figure.caption.10}{}}
\newlabel{fig: GT}{{8j}{18}{GT\relax }{figure.caption.10}{}}
\newlabel{sub@fig: GT}{{j}{18}{GT\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces   不同方法在LOL测试数据集上的视觉表现。 \relax }}{18}{figure.caption.10}\protected@file@percent }
\newlabel{fig: LOL}{{8}{18}{不同方法在LOL测试数据集上的视觉表现。 \relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}消融实验}{18}{subsubsection.4.1.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces   Transformer分支和Transformer预训练权重尺寸和SCConv对模型的影响。 \relax }}{18}{table.caption.11}\protected@file@percent }
\newlabel{tab: Ablation Study}{{3}{18}{Transformer分支和Transformer预训练权重尺寸和SCConv对模型的影响。 \relax }{table.caption.11}{}}
\newlabel{LastPage}{{}{18}{}{page.18}{}}
\xdef\lastpage@lastpage{18}
\xdef\lastpage@lastpageHy{18}
\gdef \@abspage@last{18}
