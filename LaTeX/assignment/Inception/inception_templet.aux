\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\citation{liu2021retinex,xu2020learning}
\citation{ueng1995gamma}
\citation{stark2000adaptive}
\citation{land1971lightness}
\citation{liu2021benchmarking}
\citation{dai2019fractional}
\citation{ma2019improved}
\citation{cooper2004analysis}
\citation{stark2000adaptive}
\citation{dong2010fast}
\@writefile{toc}{\contentsline {section}{\numberline {1}立题依据}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}课题的研究意义}{3}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}国内外研究现状分析}{3}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}传统低照度图像增强方法}{3}{subsubsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{基于 Retinex 的方法}{3}{subsubsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{基于直方图的方法}{3}{subsubsection.1.2.1}\protected@file@percent }
\citation{lore2017llnet}
\citation{tang2023low}
\citation{lore2017llnet}
\citation{lv2018mbllen}
\citation{wang2018gladnet}
\citation{lu2020tbefn}
\citation{li2021low}
\citation{ravirathinam2021c}
\citation{lim2020dslr}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces   直方图均衡化示意图 \relax }}{4}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: Histogram equalization}{{1}{4}{直方图均衡化示意图 \relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {paragraph}{基于图像反相的方法}{4}{figure.caption.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}基于深度学习的弱光图像增强方法}{4}{subsubsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{有监督学习}{4}{subsubsection.1.2.2}\protected@file@percent }
\citation{wei2018deep}
\citation{shen2017msr}
\citation{zhang2019kindling}
\citation{jiang2021enlightengan}
\citation{fu2022gan}
\citation{ni2020towards}
\citation{zhang2021unsupervised}
\citation{qiao2021deep}
\citation{robert2018hybridnet}
\citation{zhu2020zero}
\citation{zhang2019zero}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces   RetinexNet算法结构图。主要由三个部分组成，分解(Decomposition)，调节(Adjustment)和重构(Reconstruction)。 \relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig: RetinexNet}{{2}{5}{RetinexNet算法结构图。主要由三个部分组成，分解(Decomposition)，调节(Adjustment)和重构(Reconstruction)。 \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {paragraph}{半监督学习}{5}{figure.caption.2}\protected@file@percent }
\citation{cui2022illumination}
\citation{carion2020end}
\citation{wang2023ultra}
\citation{liu2021benchmarking}
\citation{yang2021locally,zhang2020attention}
\citation{li2018multi,zamir2020learning}
\citation{li2020visual}
\@writefile{toc}{\contentsline {paragraph}{Zero-Shot 学习}{6}{figure.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{基于 Transformer 的方法}{6}{figure.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}研究方案}{6}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}研究目标}{6}{subsection.2.1}\protected@file@percent }
\newlabel{fig: input}{{\caption@xref {fig: input}{ on input line 208}}{6}{研究目标}{figure.caption.3}{}}
\newlabel{sub@fig: input}{{}{6}{研究目标}{figure.caption.3}{}}
\newlabel{fig: LLNet_VE_LOL}{{\caption@xref {fig: LLNet_VE_LOL}{ on input line 214}}{6}{研究目标}{figure.caption.3}{}}
\newlabel{sub@fig: LLNet_VE_LOL}{{}{6}{研究目标}{figure.caption.3}{}}
\newlabel{fig: RetinexNet_VE_LOL}{{\caption@xref {fig: RetinexNet_VE_LOL}{ on input line 220}}{6}{研究目标}{figure.caption.3}{}}
\newlabel{sub@fig: RetinexNet_VE_LOL}{{}{6}{研究目标}{figure.caption.3}{}}
\newlabel{fig: MBLLEN_LOL}{{\caption@xref {fig: MBLLEN_LOL}{ on input line 226}}{6}{研究目标}{figure.caption.3}{}}
\newlabel{sub@fig: MBLLEN_LOL}{{}{6}{研究目标}{figure.caption.3}{}}
\newlabel{fig: EnlightenGAN_VE_LOL}{{\caption@xref {fig: EnlightenGAN_VE_LOL}{ on input line 232}}{6}{研究目标}{figure.caption.3}{}}
\newlabel{sub@fig: EnlightenGAN_VE_LOL}{{}{6}{研究目标}{figure.caption.3}{}}
\newlabel{fig: RRDNet_VE_LOL}{{\caption@xref {fig: RRDNet_VE_LOL}{ on input line 238}}{6}{研究目标}{figure.caption.3}{}}
\newlabel{sub@fig: RRDNet_VE_LOL}{{}{6}{研究目标}{figure.caption.3}{}}
\newlabel{fig: DRBN_VE_LOL}{{\caption@xref {fig: DRBN_VE_LOL}{ on input line 244}}{6}{研究目标}{figure.caption.3}{}}
\newlabel{sub@fig: DRBN_VE_LOL}{{}{6}{研究目标}{figure.caption.3}{}}
\newlabel{fig: Zero-DCE++}{{\caption@xref {fig: Zero-DCE++}{ on input line 250}}{6}{研究目标}{figure.caption.3}{}}
\newlabel{sub@fig: Zero-DCE++}{{}{6}{研究目标}{figure.caption.3}{}}
\newlabel{fig: KinD++}{{\caption@xref {fig: KinD++}{ on input line 256}}{6}{研究目标}{figure.caption.3}{}}
\newlabel{sub@fig: KinD++}{{}{6}{研究目标}{figure.caption.3}{}}
\newlabel{fig: URetinexNet}{{\caption@xref {fig: URetinexNet}{ on input line 262}}{6}{研究目标}{figure.caption.3}{}}
\newlabel{sub@fig: URetinexNet}{{}{6}{研究目标}{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces   不同算法对从 VE-LOL-L 数据集采样的低照度图像的可视化结果。 \relax }}{6}{figure.caption.3}\protected@file@percent }
\newlabel{fig: VE-LOL-L Visual}{{3}{6}{不同算法对从 VE-LOL-L 数据集采样的低照度图像的可视化结果。 \relax }{figure.caption.3}{}}
\citation{xu2023low}
\citation{zhu2020eemefn}
\citation{zhu2020eemefn}
\citation{rana2021edge}
\citation{rana2021edge}
\citation{chen2018learning}
\citation{xu2023low}
\citation{wang2004image}
\citation{chen2018learning}
\citation{xu2023low}
\citation{wang2004image}
\citation{zhu2020eemefn,rana2021edge}
\newlabel{fig: EEMEFN}{{4a}{7}{该 LLIE 结构源自\cite {zhu2020eemefn},如其 Multi-Exposure Fusion 部分采用多曝光融合结构,与由 Initial image 生成的边缘图进行 Concat, 后续通过一个 U-Net 网络进一步恢复图像。\relax }{figure.caption.4}{}}
\newlabel{sub@fig: EEMEFN}{{a}{7}{该 LLIE 结构源自\cite {zhu2020eemefn},如其 Multi-Exposure Fusion 部分采用多曝光融合结构,与由 Initial image 生成的边缘图进行 Concat, 后续通过一个 U-Net 网络进一步恢复图像。\relax }{figure.caption.4}{}}
\newlabel{fig: EdgeNet}{{4b}{7}{该 LLIE 结构源自\cite {rana2021edge}使用 EdgeNet 首先从低光图像中过滤边缘，EnhanceNet 反复使用上采样和下采样块的组合，从局部到全局逐渐提取特征，并消除伪影和噪声。\relax }{figure.caption.4}{}}
\newlabel{sub@fig: EdgeNet}{{b}{7}{该 LLIE 结构源自\cite {rana2021edge}使用 EdgeNet 首先从低光图像中过滤边缘，EnhanceNet 反复使用上采样和下采样块的组合，从局部到全局逐渐提取特征，并消除伪影和噪声。\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces   边缘图像指导弱光图像增强的传统架构。 \relax }}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig: Traditional Architecture}{{4}{7}{边缘图像指导弱光图像增强的传统架构。 \relax }{figure.caption.4}{}}
\newlabel{fig: Input}{{5a}{7}{Input\relax }{figure.caption.5}{}}
\newlabel{sub@fig: Input}{{a}{7}{Input\relax }{figure.caption.5}{}}
\newlabel{fig: Structure of (a)}{{5b}{7}{Structure of (a)\relax }{figure.caption.5}{}}
\newlabel{sub@fig: Structure of (a)}{{b}{7}{Structure of (a)\relax }{figure.caption.5}{}}
\newlabel{fig: SNR (CVPR 2022)}{{5c}{7}{SNR (CVPR 2022)\relax }{figure.caption.5}{}}
\newlabel{sub@fig: SNR (CVPR 2022)}{{c}{7}{SNR (CVPR 2022)\relax }{figure.caption.5}{}}
\newlabel{fig: Structure Modeling}{{5d}{7}{Structure Modeling\relax }{figure.caption.5}{}}
\newlabel{sub@fig: Structure Modeling}{{d}{7}{Structure Modeling\relax }{figure.caption.5}{}}
\newlabel{fig: SMG-LLIE}{{5e}{7}{SMG-LLIE\relax }{figure.caption.5}{}}
\newlabel{sub@fig: SMG-LLIE}{{e}{7}{SMG-LLIE\relax }{figure.caption.5}{}}
\newlabel{fig: Ground Truth}{{5f}{7}{Ground Truth\relax }{figure.caption.5}{}}
\newlabel{sub@fig: Ground Truth}{{f}{7}{Ground Truth\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces   SID-sRGB\cite  {chen2018learning}中一张弱光图片, 通过SOTA方法 (c) 和\cite  {xu2023low}提出的方法 (e)增强。作者的方法可以从输入的图像中合成结构图(d)，使细节更清晰，对比度更清晰，颜色更鲜艳。虽然(c)的 PSNR 为 28.17，但其 SSIM 低为 0.75。作者的方法在dB和SSIM\cite  {wang2004image}的得分都很高，分别为28.60 dB 和 0.80。 \relax }}{7}{figure.caption.5}\protected@file@percent }
\newlabel{fig: Structural Information}{{5}{7}{SID-sRGB\cite {chen2018learning}中一张弱光图片, 通过SOTA方法 (c) 和\cite {xu2023low}提出的方法 (e)增强。作者的方法可以从输入的图像中合成结构图(d)，使细节更清晰，对比度更清晰，颜色更鲜艳。虽然(c)的 PSNR 为 28.17，但其 SSIM 低为 0.75。作者的方法在dB和SSIM\cite {wang2004image}的得分都很高，分别为28.60 dB 和 0.80。 \relax }{figure.caption.5}{}}
\citation{xu2023low}
\citation{pietikainen2010local}
\citation{woo2018cbam}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}研究内容}{8}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}拟解决的关键问题}{8}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}拟采取的研究方法}{8}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}注意力机制}{8}{subsubsection.2.4.1}\protected@file@percent }
\citation{ramachandran2019stand}
\citation{woo2018cbam}
\citation{li2023scconv}
\citation{chen2018learning}
\citation{chen2018learning,zamir2021learning}
\citation{chen2018learning}
\citation{chen2018learning,zamir2021learning}
\citation{meng2020gia}
\citation{chen2018learning,zamir2021learning}
\citation{meng2020gia}
\citation{chen2018learning,meng2020gia,zamir2021learning}
\citation{zhou2018unet++,zhou2019unet++}
\citation{yang2021locally,zhang2020attention}
\citation{li2018multi,zamir2020learning}
\citation{li2020visual}
\citation{xu2020learning}
\citation{vaswani2017attention}
\citation{dosovitskiy2020image}
\citation{wang2022ultrahighdefinition}
\citation{wang2021uformer}
\citation{chen2023cross}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}U-Net网络结构}{9}{subsubsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}CNN网络结构}{9}{subsubsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}Transformer网络结构}{9}{subsubsection.2.4.4}\protected@file@percent }
\citation{burt1984pyramid}
\citation{wang2022uformer}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}技术路线}{10}{subsection.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces   我们提出的技术框架。 \relax }}{10}{figure.caption.6}\protected@file@percent }
\newlabel{fig: Total Architecture}{{6}{10}{我们提出的技术框架。 \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}方案及可行性研究}{10}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}初步恢复图像的生成模型}{10}{subsubsection.2.6.1}\protected@file@percent }
\citation{jain1991unsupervised,lowe2004distinctive,ojala2002multiresolution}
\citation{lisin2005combining}
\citation{peng2021conformer}
\citation{jain1991unsupervised,lowe2004distinctive,ojala2002multiresolution}
\citation{lisin2005combining}
\citation{karu1996there}
\citation{szegedy2016rethinking}
\citation{peng2021conformer}
\citation{peng2021conformer}
\citation{woo2018cbam}
\newlabel{fig: First Architecture}{{7a}{12}{Parallel Architecture\relax }{figure.caption.7}{}}
\newlabel{sub@fig: First Architecture}{{a}{12}{Parallel Architecture\relax }{figure.caption.7}{}}
\newlabel{fig: Up-sampling and down-sampling}{{7b}{12}{Up-sampling and Down-sampling\relax }{figure.caption.7}{}}
\newlabel{sub@fig: Up-sampling and down-sampling}{{b}{12}{Up-sampling and Down-sampling\relax }{figure.caption.7}{}}
\newlabel{fig: The proposed initial architecture(Abstract Picture)}{{7c}{12}{Thumbnail of PACUT\relax }{figure.caption.7}{}}
\newlabel{sub@fig: The proposed initial architecture(Abstract Picture)}{{c}{12}{Thumbnail of PACUT\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces   我们提出的初步恢复图架构。图\ref {fig: First Architecture} CNN 分支和 Transformer 分支以及 FCU (Feature Coupling Unit)。图\ref {fig: Up-sampling and down-sampling} 特征映射和 Patch embeddings 空间对齐的上采样和下采样过程。 图\ref {fig: The proposed initial architecture(Abstract Picture)} PACUT 的缩略图。PACUT 结构受 Conformer\cite  {peng2021conformer}启发，将原来结构中 CNN 分支的 ResNet 结构修改为 U-Net 结构。其采用一个 U-Net 和 ViT 的并行架构，通过 U-Net 结构得到一个弱恢复的弱特征图 $\mathcal  {F}_2$，通过 ViT 融合的特征可以初步增强弱特征图 $\mathcal  {F}_2$，ViT 的输出经过 Patch Expanding 的特征图 $\mathcal  {F}_3$ 经过与 U-Net 输出的特征图 $\mathcal  {F}_2$ 融合之后得到一个初步恢复的图片 output image，用以后续参与图片的进一步恢复。 \relax }}{12}{figure.caption.7}\protected@file@percent }
\newlabel{fig: PACUT}{{7}{12}{我们提出的初步恢复图架构。图\ref {fig: First Architecture} CNN 分支和 Transformer 分支以及 FCU (Feature Coupling Unit)。图\ref {fig: Up-sampling and down-sampling} 特征映射和 Patch embeddings 空间对齐的上采样和下采样过程。 图\ref {fig: The proposed initial architecture(Abstract Picture)} PACUT 的缩略图。PACUT 结构受 Conformer\cite {peng2021conformer}启发，将原来结构中 CNN 分支的 ResNet 结构修改为 U-Net 结构。其采用一个 U-Net 和 ViT 的并行架构，通过 U-Net 结构得到一个弱恢复的弱特征图 $\mathcal {F}_2$，通过 ViT 融合的特征可以初步增强弱特征图 $\mathcal {F}_2$，ViT 的输出经过 Patch Expanding 的特征图 $\mathcal {F}_3$ 经过与 U-Net 输出的特征图 $\mathcal {F}_2$ 融合之后得到一个初步恢复的图片 output image，用以后续参与图片的进一步恢复。 \relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {paragraph}{CNN 分支}{12}{figure.caption.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces   CNN分支及其所属的模块。 \relax }}{13}{figure.caption.8}\protected@file@percent }
\newlabel{fig: U-Net and AM}{{8}{13}{CNN分支及其所属的模块。 \relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {paragraph}{注意力残差多尺度块}{13}{figure.caption.8}\protected@file@percent }
\citation{huber1992robust}
\citation{johnson2016perceptual}
\citation{wang2004image}
\@writefile{toc}{\contentsline {paragraph}{Transformer分支}{14}{figure.caption.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Transformer编码器}{14}{figure.caption.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{特征融合模块}{14}{figure.caption.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{损失函数}{14}{figure.caption.9}\protected@file@percent }
\newlabel{eq: loss function}{{2.1}{14}{损失函数}{equation.2.1}{}}
\citation{liu2017richer}
\citation{xie2015holistically}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces   融合模块的结构。 \relax }}{15}{figure.caption.9}\protected@file@percent }
\newlabel{fig: Fusion Block}{{9}{15}{融合模块的结构。 \relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2}边缘检测网络}{15}{subsubsection.2.6.2}\protected@file@percent }
\newlabel{fig: LLI}{{10a}{15}{LLI\relax }{figure.caption.10}{}}
\newlabel{sub@fig: LLI}{{a}{15}{LLI\relax }{figure.caption.10}{}}
\newlabel{fig: LLI_canny}{{10b}{15}{LLI Canny\relax }{figure.caption.10}{}}
\newlabel{sub@fig: LLI_canny}{{b}{15}{LLI Canny\relax }{figure.caption.10}{}}
\newlabel{fig: LLI_rcf}{{10c}{15}{LLI RCF\relax }{figure.caption.10}{}}
\newlabel{sub@fig: LLI_rcf}{{c}{15}{LLI RCF\relax }{figure.caption.10}{}}
\newlabel{fig: LLI_hog}{{10d}{15}{LLI HOG\relax }{figure.caption.10}{}}
\newlabel{sub@fig: LLI_hog}{{d}{15}{LLI HOG\relax }{figure.caption.10}{}}
\newlabel{fig: LLI_lbp}{{10e}{15}{LLI LBP\relax }{figure.caption.10}{}}
\newlabel{sub@fig: LLI_lbp}{{e}{15}{LLI LBP\relax }{figure.caption.10}{}}
\newlabel{fig: GI}{{10f}{15}{GT\relax }{figure.caption.10}{}}
\newlabel{sub@fig: GI}{{f}{15}{GT\relax }{figure.caption.10}{}}
\newlabel{fig: GT_canny}{{10g}{15}{GT Canny\relax }{figure.caption.10}{}}
\newlabel{sub@fig: GT_canny}{{g}{15}{GT Canny\relax }{figure.caption.10}{}}
\newlabel{fig: GT_rcf}{{10h}{15}{GT RCF\relax }{figure.caption.10}{}}
\newlabel{sub@fig: GT_rcf}{{h}{15}{GT RCF\relax }{figure.caption.10}{}}
\newlabel{fig: GT_hog}{{10i}{15}{GT HOG\relax }{figure.caption.10}{}}
\newlabel{sub@fig: GT_hog}{{i}{15}{GT HOG\relax }{figure.caption.10}{}}
\newlabel{fig: GT_lbp}{{10j}{15}{GT LBP\relax }{figure.caption.10}{}}
\newlabel{sub@fig: GT_lbp}{{j}{15}{GT LBP\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces   基于 LOL-v2 弱光数据集的边缘信息。 \relax }}{15}{figure.caption.10}\protected@file@percent }
\newlabel{fig: LLI Structure Information}{{10}{15}{基于 LOL-v2 弱光数据集的边缘信息。 \relax }{figure.caption.10}{}}
\citation{simonyan2014very}
\citation{simonyan2014very}
\citation{maini2009study}
\citation{liu2017richer}
\citation{maini2009study}
\newlabel{fig: origin image}{{11a}{16}{origin image\relax }{figure.caption.11}{}}
\newlabel{sub@fig: origin image}{{a}{16}{origin image\relax }{figure.caption.11}{}}
\newlabel{fig: RCF_GT}{{11b}{16}{GT\relax }{figure.caption.11}{}}
\newlabel{sub@fig: RCF_GT}{{b}{16}{GT\relax }{figure.caption.11}{}}
\newlabel{fig: conv3_1}{{11c}{16}{conv3\_1\relax }{figure.caption.11}{}}
\newlabel{sub@fig: conv3_1}{{c}{16}{conv3\_1\relax }{figure.caption.11}{}}
\newlabel{fig: conv3_2}{{11d}{16}{conv3\_2\relax }{figure.caption.11}{}}
\newlabel{sub@fig: conv3_2}{{d}{16}{conv3\_2\relax }{figure.caption.11}{}}
\newlabel{fig: conv3_3}{{11e}{16}{conv3\_3\relax }{figure.caption.11}{}}
\newlabel{sub@fig: conv3_3}{{e}{16}{conv3\_3\relax }{figure.caption.11}{}}
\newlabel{fig: conv4_1}{{11f}{16}{conv4\_1\relax }{figure.caption.11}{}}
\newlabel{sub@fig: conv4_1}{{f}{16}{conv4\_1\relax }{figure.caption.11}{}}
\newlabel{fig: conv4_2}{{11g}{16}{conv4\_2\relax }{figure.caption.11}{}}
\newlabel{sub@fig: conv4_2}{{g}{16}{conv4\_2\relax }{figure.caption.11}{}}
\newlabel{fig: conv4_3}{{11h}{16}{conv4\_3\relax }{figure.caption.11}{}}
\newlabel{sub@fig: conv4_3}{{h}{16}{conv4\_3\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces   建立了一个基于 VGG16\cite  {simonyan2014very} 的简单网络来产生侧输出(c-h)。我们可以看到，卷积特征逐渐变得更粗，而中间层(c、d、f、g)包含了在其他层中没有出现的基本细节。 \relax }}{16}{figure.caption.11}\protected@file@percent }
\newlabel{fig: Motivation of RCF}{{11}{16}{建立了一个基于 VGG16\cite {simonyan2014very} 的简单网络来产生侧输出(c-h)。我们可以看到，卷积特征逐渐变得更粗，而中间层(c、d、f、g)包含了在其他层中没有出现的基本细节。 \relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces   边缘检测网络。 \relax }}{17}{figure.caption.12}\protected@file@percent }
\newlabel{fig: Edge Detection Network}{{12}{17}{边缘检测网络。 \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}计划进度}{17}{subsection.2.7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces   计划进度 \relax }}{17}{table.caption.13}\protected@file@percent }
\newlabel{tab: Schedule}{{1}{17}{计划进度 \relax }{table.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}预期的研究进展}{17}{subsection.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}课题的创新性}{17}{section.3}\protected@file@percent }
\citation{wei2018deep}
\citation{cai2018learning}
\citation{wang2004image}
\citation{wang2004image}
\citation{mittal2012making}
\citation{pisano1998contrast}
\citation{li2018lightennet}
\citation{lore2017llnet}
\citation{wei2018deep}
\citation{lv2018mbllen}
\citation{jiang2021enlightengan}
\citation{guo2020zero}
\citation{zhang2019kindling}
\citation{wei2018deep}
\citation{cai2018learning}
\citation{pisano1998contrast}
\citation{li2018lightennet}
\citation{lore2017llnet}
\citation{wei2018deep}
\citation{zhang2019kindling}
\citation{lv2018mbllen}
\citation{jiang2021enlightengan}
\citation{guo2020zero}
\@writefile{toc}{\contentsline {section}{\numberline {4}研究基础}{18}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}已完成工作}{18}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}初步恢复图像的生成模型实验结果}{18}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}数据集和评价指标}{18}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}对比试验}{18}{subsubsection.4.1.3}\protected@file@percent }
\bibstyle{unsrt}
\bibdata{reference}
\bibcite{liu2021retinex}{1}
\bibcite{xu2020learning}{2}
\bibcite{ueng1995gamma}{3}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces   LOL和SCIE数据集在各方法下的对比值，其中红色表示最优，蓝色表示次优，$↑$表示越高越好，$↓$表示越低越好。 \relax }}{19}{table.caption.14}\protected@file@percent }
\newlabel{tab: Quantitative Comparisons on LOL-test and SCI testing datasets}{{2}{19}{LOL和SCIE数据集在各方法下的对比值，其中红色表示最优，蓝色表示次优，$↑$表示越高越好，$↓$表示越低越好。 \relax }{table.caption.14}{}}
\newlabel{fig: LLI Input}{{13a}{19}{Input\relax }{figure.caption.15}{}}
\newlabel{sub@fig: LLI Input}{{a}{19}{Input\relax }{figure.caption.15}{}}
\newlabel{fig: LightenNet}{{13b}{19}{LightenNet\relax }{figure.caption.15}{}}
\newlabel{sub@fig: LightenNet}{{b}{19}{LightenNet\relax }{figure.caption.15}{}}
\newlabel{fig: LLI LLNet}{{13c}{19}{LLNet\relax }{figure.caption.15}{}}
\newlabel{sub@fig: LLI LLNet}{{c}{19}{LLNet\relax }{figure.caption.15}{}}
\newlabel{fig: LLI RetinexNet}{{13d}{19}{RetinexNet\relax }{figure.caption.15}{}}
\newlabel{sub@fig: LLI RetinexNet}{{d}{19}{RetinexNet\relax }{figure.caption.15}{}}
\newlabel{fig: KinD}{{13e}{19}{KinD\relax }{figure.caption.15}{}}
\newlabel{sub@fig: KinD}{{e}{19}{KinD\relax }{figure.caption.15}{}}
\newlabel{fig: MBLLEN}{{13f}{19}{MBLLEN\relax }{figure.caption.15}{}}
\newlabel{sub@fig: MBLLEN}{{f}{19}{MBLLEN\relax }{figure.caption.15}{}}
\newlabel{fig: LLI EnlightenGAN}{{13g}{19}{EnlightenGAN\relax }{figure.caption.15}{}}
\newlabel{sub@fig: LLI EnlightenGAN}{{g}{19}{EnlightenGAN\relax }{figure.caption.15}{}}
\newlabel{fig: Zero-DCE}{{13h}{19}{Zero-DCE\relax }{figure.caption.15}{}}
\newlabel{sub@fig: Zero-DCE}{{h}{19}{Zero-DCE\relax }{figure.caption.15}{}}
\newlabel{fig: Ours}{{13i}{19}{Ours\relax }{figure.caption.15}{}}
\newlabel{sub@fig: Ours}{{i}{19}{Ours\relax }{figure.caption.15}{}}
\newlabel{fig: GT}{{13j}{19}{GT\relax }{figure.caption.15}{}}
\newlabel{sub@fig: GT}{{j}{19}{GT\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces   不同方法在LOL测试数据集上的视觉表现。 \relax }}{19}{figure.caption.15}\protected@file@percent }
\newlabel{fig: LOL}{{13}{19}{不同方法在LOL测试数据集上的视觉表现。 \relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}消融实验}{19}{subsubsection.4.1.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces   Transformer分支和Transformer预训练权重尺寸和SCConv对模型的影响。 \relax }}{19}{table.caption.16}\protected@file@percent }
\newlabel{tab: Ablation Study}{{3}{19}{Transformer分支和Transformer预训练权重尺寸和SCConv对模型的影响。 \relax }{table.caption.16}{}}
\bibcite{stark2000adaptive}{4}
\bibcite{land1971lightness}{5}
\bibcite{liu2021benchmarking}{6}
\bibcite{dai2019fractional}{7}
\bibcite{ma2019improved}{8}
\bibcite{cooper2004analysis}{9}
\bibcite{202013}{10}
\bibcite{dong2010fast}{11}
\bibcite{lore2017llnet}{12}
\bibcite{tang2023low}{13}
\bibcite{lv2018mbllen}{14}
\bibcite{wang2018gladnet}{15}
\bibcite{lu2020tbefn}{16}
\bibcite{li2021low}{17}
\bibcite{ravirathinam2021c}{18}
\bibcite{lim2020dslr}{19}
\bibcite{wei2018deep}{20}
\bibcite{shen2017msr}{21}
\bibcite{zhang2019kindling}{22}
\bibcite{cui2022illumination}{23}
\bibcite{carion2020end}{24}
\bibcite{wang2023ultra}{25}
\bibcite{jiang2021enlightengan}{26}
\bibcite{fu2022gan}{27}
\bibcite{ni2020towards}{28}
\bibcite{zhang2021unsupervised}{29}
\bibcite{qiao2021deep}{30}
\bibcite{robert2018hybridnet}{31}
\bibcite{zhu2020zero}{32}
\bibcite{zhang2019zero}{33}
\bibcite{cai2018learning}{34}
\bibcite{guo2016lime}{35}
\bibcite{singh2016contrast}{36}
\bibcite{chai2014root}{37}
\bibcite{kellman2005image}{38}
\bibcite{yu2017low}{39}
\bibcite{zhang2018unreasonable}{40}
\bibcite{sheikh2005information}{41}
\bibcite{russakovsky2015imagenet}{42}
\bibcite{ignatov2018wespe}{43}
\bibcite{zhu2015low}{44}
\bibcite{mittal2012making}{45}
\bibcite{fu2016weighted}{46}
\bibcite{ma2017learning}{47}
\bibcite{ke2021musiq}{48}
\bibcite{talebi2018nima}{49}
\bibcite{fang2020perceptual}{50}
\bibcite{yang2021locally}{51}
\bibcite{zhang2020attention}{52}
\bibcite{li2018multi}{53}
\bibcite{zamir2020learning}{54}
\bibcite{li2020visual}{55}
\bibcite{xu2023low}{56}
\bibcite{zhu2020eemefn}{57}
\bibcite{rana2021edge}{58}
\bibcite{chen2018learning}{59}
\bibcite{wang2004image}{60}
\bibcite{pietikainen2010local}{61}
\bibcite{woo2018cbam}{62}
\bibcite{ramachandran2019stand}{63}
\bibcite{li2023scconv}{64}
\bibcite{zamir2021learning}{65}
\bibcite{meng2020gia}{66}
\bibcite{zhou2018unet++}{67}
\bibcite{zhou2019unet++}{68}
\bibcite{vaswani2017attention}{69}
\bibcite{dosovitskiy2020image}{70}
\bibcite{wang2022ultrahighdefinition}{71}
\bibcite{wang2021uformer}{72}
\bibcite{chen2023cross}{73}
\bibcite{burt1984pyramid}{74}
\bibcite{wang2022uformer}{75}
\bibcite{peng2021conformer}{76}
\bibcite{jain1991unsupervised}{77}
\bibcite{lowe2004distinctive}{78}
\bibcite{ojala2002multiresolution}{79}
\bibcite{lisin2005combining}{80}
\bibcite{karu1996there}{81}
\bibcite{szegedy2016rethinking}{82}
\bibcite{huber1992robust}{83}
\bibcite{johnson2016perceptual}{84}
\bibcite{liu2017richer}{85}
\bibcite{xie2015holistically}{86}
\bibcite{simonyan2014very}{87}
\bibcite{maini2009study}{88}
\bibcite{pisano1998contrast}{89}
\bibcite{li2018lightennet}{90}
\bibcite{guo2020zero}{91}
\newlabel{LastPage}{{}{25}{}{page.25}{}}
\xdef\lastpage@lastpage{25}
\xdef\lastpage@lastpageHy{25}
\gdef \@abspage@last{25}
