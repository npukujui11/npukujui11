\contentsline {section}{\numberline {1}Pre-Knowledge}{1}{section.1}%
\contentsline {subsection}{\numberline {1.1}Transformer}{1}{subsection.1.1}%
\contentsline {subsubsection}{\numberline {1.1.1}Idea}{2}{subsubsection.1.1.1}%
\contentsline {subsubsection}{\numberline {1.1.2}Architecture}{2}{subsubsection.1.1.2}%
\contentsline {paragraph}{Encoder}{4}{figure.caption.1}%
\contentsline {paragraph}{Decoder}{4}{figure.caption.1}%
\contentsline {subsubsection}{\numberline {1.1.3}Attention Mechanism}{4}{subsubsection.1.1.3}%
\contentsline {paragraph}{Scaled dot-product attention}{4}{subsubsection.1.1.3}%
\contentsline {paragraph}{Multi-head attention}{6}{equation.1.2}%
\contentsline {section}{\numberline {2}Paper reading}{6}{section.2}%
\contentsline {subsection}{\numberline {2.1}Ultra-High-Definition Low-Light Image Enhancement}{6}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}Introduce}{6}{subsubsection.2.1.1}%
\contentsline {subsubsection}{\numberline {2.1.2}Innovation}{6}{subsubsection.2.1.2}%
\contentsline {paragraph}{Axis-based Transformer Block}{7}{subsubsection.2.1.2}%
\contentsline {paragraph}{Dual Gated Feed-forward Network(DGFN)}{7}{subsubsection.2.1.2}%
\contentsline {paragraph}{Cross-layer Attention Fusion Block}{8}{equation.2.5}%
\contentsline {subsubsection}{\numberline {2.1.3}Result}{8}{subsubsection.2.1.3}%
\contentsline {section}{\numberline {3}个人工作进展}{10}{section.3}%
\contentsline {subsection}{\numberline {3.1}思考}{10}{subsection.3.1}%
\contentsline {section}{\numberline {4}下周工作计划}{10}{section.4}%
