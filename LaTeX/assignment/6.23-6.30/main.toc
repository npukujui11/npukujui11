\contentsline {section}{\numberline {1}Pre-Knowledge}{1}{section.1}%
\contentsline {subsection}{\numberline {1.1}Transformer}{1}{subsection.1.1}%
\contentsline {subsubsection}{\numberline {1.1.1}Idea}{2}{subsubsection.1.1.1}%
\contentsline {subsubsection}{\numberline {1.1.2}Architecture}{2}{subsubsection.1.1.2}%
\contentsline {paragraph}{Encoder}{2}{figure.caption.1}%
\contentsline {paragraph}{Decoder}{2}{figure.caption.1}%
\contentsline {subsubsection}{\numberline {1.1.3}Attention Mechanism}{4}{subsubsection.1.1.3}%
\contentsline {paragraph}{Scaled dot-product attention}{4}{subsubsection.1.1.3}%
\contentsline {paragraph}{Multi-head attention}{5}{equation.1.2}%
\contentsline {section}{\numberline {2}Paper reading}{5}{section.2}%
\contentsline {subsection}{\numberline {2.1}Ultra-High-Definition Low-Light Image Enhancement}{5}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}Introduce}{5}{subsubsection.2.1.1}%
\contentsline {subsubsection}{\numberline {2.1.2}Innovation}{5}{subsubsection.2.1.2}%
\contentsline {paragraph}{Axis-based Transformer Block}{6}{subsubsection.2.1.2}%
\contentsline {paragraph}{Dual Gated Feed-forward Network(DGFN)}{6}{subsubsection.2.1.2}%
\contentsline {paragraph}{Cross-layer Attention Fusion Block}{7}{equation.2.5}%
\contentsline {subsubsection}{\numberline {2.1.3}Result}{7}{subsubsection.2.1.3}%
\contentsline {section}{\numberline {3}个人工作进展}{7}{section.3}%
\contentsline {subsection}{\numberline {3.1}思考}{7}{subsection.3.1}%
\contentsline {section}{\numberline {4}下周工作计划}{9}{section.4}%
